{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import os\n",
    "import math\n",
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Esperamos trabalhar no diretório\n",
      "C:\\Git\\Estudo_CDados\\Atividade_1\n"
     ]
    }
   ],
   "source": [
    "print('Esperamos trabalhar no diretório')\n",
    "print(os.getcwd())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Método de Limpeza:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cleanup(text):\n",
    "    texto_sem_rt = text.replace(\"rt\", \"\")\n",
    "    \"\"\"\n",
    "        Função de limpeza muito simples que troca alguns sinais básicos por espaços\n",
    "    \"\"\"\n",
    "    punctuation = \"[!\\-:?;.@//]\" # Note que os sinais [] são delimitadores de um conjunto.\n",
    "    pattern = re.compile(punctuation)\n",
    "    text_subbed = re.sub(pattern, '', texto_sem_rt)\n",
    "    return text_subbed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [],
   "source": [
    "nome_planilha = 'Spacex.xlsx'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Função de Classificação:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [],
   "source": [
    "def transforma_planilha_string(nome_planilha):\n",
    "    #lendo a planilha\n",
    "    dados = pd.ExcelFile(nome_planilha)\n",
    "    \n",
    "    ##treinamento\n",
    "    treinamento = pd.read_excel(dados, 'Treinamento')\n",
    "    treinamento_reindexado = treinamento.set_index(\"Treinamento\")\n",
    "    treinamento_relevante = treinamento_reindexado.qual[treinamento_reindexado.qual == 1]\n",
    "    treinamento_irrelevante = treinamento_reindexado.qual[treinamento_reindexado.qual == 0]\n",
    "    \n",
    "    #tranformando em string o treinamento\n",
    "    string_relevante = \"\"\n",
    "    for plvrs in treinamento_relevante.index:\n",
    "        string_relevante = string_relevante + plvrs\n",
    "        \n",
    "    string_irrelevante = \"\"\n",
    "    for plvras in treinamento_irrelevante.index:\n",
    "        string_irrelevante = string_irrelevante + plvras\n",
    "        \n",
    "    #utilizando o método de limpeza já implementado no treinamento\n",
    "    treinamento_relevante_limpo = cleanup(string_relevante.lower())\n",
    "    treinamento_irrelevante_limpo = cleanup(string_irrelevante.lower())\n",
    "    \n",
    "    #separando em relevante e irrelevante o treinamento\n",
    "    treinamento_relevante_splitado = treinamento_relevante_limpo.split()\n",
    "    treinamento_irrelevante_splitado = treinamento_irrelevante_limpo.split()\n",
    "    \n",
    "    #transformando em panda.Series o treinamento\n",
    "    series_treinamento_relevante = pd.Series(treinamento_relevante_splitado)\n",
    "    series_treinamento_irrelevante = pd.Series(treinamento_irrelevante_splitado)\n",
    "    \n",
    "    ##teste\n",
    "    teste = pd.read_excel(dados, 'Teste')\n",
    "    teste_reindexado = teste.set_index(\"Teste\")\n",
    "    teste_relevante = teste_reindexado.qual[teste_reindexado.qual == 1]\n",
    "    teste_irrelevante = teste_reindexado.qual[teste_reindexado.qual == 0]\n",
    "    \n",
    "    #transformando em string o teste\n",
    "    string_relevante_teste = \"\"\n",
    "    for plv in teste_relevante.index:\n",
    "        string_relevante_teste = string_relevante_teste + plv\n",
    "        \n",
    "    string_irrelevante_teste = \"\"\n",
    "    for pl in teste_irrelevante.index:\n",
    "        string_irrelevante_teste = string_irrelevante_teste + pl\n",
    "        \n",
    "    #utilizando o método de limpeza já implementado no teste\n",
    "    teste_relevante_limpo  = cleanup(string_relevante_teste.lower())\n",
    "    teste_irrelevante_limpo = cleanup(string_irrelevante_teste.lower())\n",
    "    \n",
    "    #separando em relevante e irrelevante o teste\n",
    "    teste_relevante_splitado = teste_relevante_limpo.split()\n",
    "    teste_irrelevante_splitado = teste_irrelevante_limpo.split()\n",
    "    \n",
    "    #transformando em panda.Series o teste\n",
    "    series_teste_relevante = pd.Series(teste_relevante_splitado)\n",
    "    series_teste_irrelevante = pd.Series(teste_irrelevante_splitado)\n",
    "    \n",
    "    return series_treinamento_relevante, series_teste_relevante, series_teste_relevante, series_teste_irrelevante"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Realizando laplace smoothin"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {},
   "outputs": [],
   "source": [
    "def laplace_smoothin(catg_1,catg_2,tseries):\n",
    "    fator_correção = 10\n",
    "    \n",
    "    counting_catg1 = catg_1.value_counts()\n",
    "    counting_catg2 = catg_2.value_counts()\n",
    "    counting_tseries = tseries.value_counts()\n",
    "    \n",
    "    #multiply_catg1_tseries = counting_catg1 * counting_tseries\n",
    "    #multiply_catg2_tseries = counting_catg2 * counting_tseries\n",
    "    \n",
    "    #print(counting_catg1)\n",
    "    \n",
    "    list_1 = list(catg_1)\n",
    "    list_2 = list(catg_2)\n",
    "    list_3 = list(tseries)\n",
    "    \n",
    "    n_words_catg1 = counting_catg1.sum()\n",
    "    n_words_catg2 = counting_catg2.sum()\n",
    "    \n",
    "    print(n_words_catg1)\n",
    "    print(len(list_1))\n",
    "    \n",
    "    tseries_setado = set(list_3)\n",
    "    \n",
    "    fill_nan_tseries = counting_tseries.fillna(0)\n",
    "    \n",
    "    add_1_tseries = fill_nan_tseries.add(1)\n",
    "    \n",
    "    result_catg1 = add_1_tseries / ( n_words_catg1 + len(tseries_setado) )\n",
    "    result_catg2 = add_1_tseries / ( n_words_catg2 + len(tseries_setado) )\n",
    "    \n",
    "    probabilidade_catg1_separada = result_catg1\n",
    "    probabilidade_catg2_separada = result_catg2\n",
    "    \n",
    "    print(probabilidade_catg1_separada)\n",
    "    print(probabilidade_catg2_separada)\n",
    "    \n",
    "    prob_catg1 = probabilidade_catg1_separada.prod()\n",
    "    prob_catg2 = probabilidade_catg2_separada.prod()\n",
    "    \n",
    "#     teste_prob_1 = []\n",
    "#     teste_prob_2 = []\n",
    "    \n",
    "#     prob_1 = 1\n",
    "#     for values in result_catg1:\n",
    "#         prob_1 = prob_1 * values\n",
    "#         teste_prob_1.append(math.e ** prob_1)\n",
    "        \n",
    "#     prob_2 = 1\n",
    "#     for values in result_catg2:\n",
    "#         prob_2 = prob_2 * values\n",
    "#         teste_prob_2.append(math.e ** prob_2)\n",
    "        \n",
    "#     prob_catg1 = 1\n",
    "#     for valores_1 in teste_prob_1:\n",
    "#         prob_catg1 = prob_catg1 * valores_1\n",
    "    \n",
    "#     prob_catg2 = 1\n",
    "#     for valores_2 in teste_prob_2:\n",
    "#         prob_catg2 = prob_catg2 * valores_2\n",
    "    \n",
    "    if prob_catg1 > prob_catg2:\n",
    "        print(\"É mais provável que faça parte da categoria 1!\")\n",
    "    else:\n",
    "        print(\"É mais provável que faça parte da categoria 2!\")\n",
    "    #print(teste_catg1)\n",
    "    \n",
    "    return prob_catg1, prob_catg2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {},
   "outputs": [],
   "source": [
    "relevante_treinamento,irrelevante_treinamento, relevante_teste, irrelevante_teste = transforma_planilha_string(nome_planilha)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2842\n",
      "2842\n",
      "a                     0.007362\n",
      "de                    0.007055\n",
      "spacex                0.007055\n",
      "da                    0.005828\n",
      "do                    0.003988\n",
      "                        ...   \n",
      "inglaterra)           0.000613\n",
      "minha                 0.000613\n",
      "energia               0.000613\n",
      "#tecmundoa            0.000613\n",
      "httpstconhakadndjx    0.000613\n",
      "Length: 418, dtype: float64\n",
      "a                     0.017582\n",
      "de                    0.016850\n",
      "spacex                0.016850\n",
      "da                    0.013919\n",
      "do                    0.009524\n",
      "                        ...   \n",
      "inglaterra)           0.001465\n",
      "minha                 0.001465\n",
      "energia               0.001465\n",
      "#tecmundoa            0.001465\n",
      "httpstconhakadndjx    0.001465\n",
      "Length: 418, dtype: float64\n",
      "É mais provável que faça parte da categoria 2!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(0.0, 0.0)"
      ]
     },
     "execution_count": 140,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "laplace_smoothin(relevante_treinamento,irrelevante_treinamento,irrelevante_teste)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
