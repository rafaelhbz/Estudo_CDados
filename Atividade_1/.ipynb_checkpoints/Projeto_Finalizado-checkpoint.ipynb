{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import os\n",
    "import math\n",
    "import re"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Checagem de diretório"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Esperamos trabalhar no diretório\n",
      "C:\\Git\\Estudo_CDados\\Atividade_1\n"
     ]
    }
   ],
   "source": [
    "print('Esperamos trabalhar no diretório')\n",
    "print(os.getcwd())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Método de limpeza\n",
    "***\n",
    "* Vale a pena ressaltar que fiz este método de limpeza baseado no que o professor Fabio Miranda nos ensinou no semestre passado em Ciência dos Dados (aprendi isso pois estou de DP dessa matéria)\n",
    "*** "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cleanup(text):\n",
    "    texto_sem_rt = text.replace(\"rt\", \"\")\n",
    "    \"\"\"\n",
    "        Função de limpeza muito simples que troca alguns sinais básicos por espaços\n",
    "    \"\"\"\n",
    "    punctuation = \"[!\\-:?;.@//]\" # Note que os sinais [] são delimitadores de um conjunto.\n",
    "    pattern = re.compile(punctuation)\n",
    "    text_subbed = re.sub(pattern, '', texto_sem_rt)\n",
    "    return text_subbed"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Nome da planilha\n",
    "***\n",
    "* Essa parte é essencial para a conclusão do projeto, pois é parâmetro de entrada da minha função\n",
    "***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "nome_planilha = 'Spacex.xlsx'\n",
    "dados = pd.ExcelFile('Spacex.xlsx')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Separando a planilha em segmento Treinamento e Teste"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "teste_planilha = pd.read_excel(dados, 'Teste')\n",
    "teste_reindexado = teste_planilha.set_index(\"Teste\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Função de classificação"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def transforma_planilha_string(nome_planilha):\n",
    "    #lendo a planilha\n",
    "    dados = nome_planilha\n",
    "    \n",
    "    ##treinamento\n",
    "    treinamento = pd.read_excel(dados, 'Treinamento')\n",
    "    treinamento_reindexado = treinamento.set_index(\"Treinamento\")\n",
    "    treinamento_relevante = treinamento_reindexado.qual[treinamento_reindexado.qual == 1]\n",
    "    treinamento_irrelevante = treinamento_reindexado.qual[treinamento_reindexado.qual == 0]\n",
    "    \n",
    "    #tranformando em string o treinamento\n",
    "    string_relevante = \"\"\n",
    "    for plvrs in treinamento_relevante.index:\n",
    "        string_relevante = string_relevante + plvrs\n",
    "        \n",
    "    string_irrelevante = \"\"\n",
    "    for plvras in treinamento_irrelevante.index:\n",
    "        string_irrelevante = string_irrelevante + plvras\n",
    "        \n",
    "    #utilizando o método de limpeza já implementado no treinamento\n",
    "    treinamento_relevante_limpo = cleanup(string_relevante.lower())\n",
    "    treinamento_irrelevante_limpo = cleanup(string_irrelevante.lower())\n",
    "    \n",
    "    #separando em relevante e irrelevante o treinamento\n",
    "    treinamento_relevante_splitado = treinamento_relevante_limpo.split()\n",
    "    treinamento_irrelevante_splitado = treinamento_irrelevante_limpo.split()\n",
    "    \n",
    "    #transformando em panda.Series o treinamento\n",
    "    #series_treinamento_relevante = pd.Series(treinamento_relevante_splitado)\n",
    "    #series_treinamento_irrelevante = pd.Series(treinamento_irrelevante_splitado)\n",
    "        \n",
    "    return treinamento_relevante_limpo, treinamento_irrelevante_limpo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "relevante, irrelevante = transforma_planilha_string(nome_planilha)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Função de contador de palavras:\n",
    "***\n",
    "* Está explicada nos comentários\n",
    "***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def numero_string_series(relevante,irrelevante,a):\n",
    "    relevante_series = pd.Series(relevante.lower().split())\n",
    "    relevante_contado = relevante_series.count()\n",
    "    \n",
    "    irrelevante_series = pd.Series(irrelevante.lower().split())\n",
    "    irrelevante_contado = irrelevante_series.count()\n",
    "    \n",
    "    prod_relevante = 1\n",
    "    prod_irrelevante = 1\n",
    "    \n",
    "    lis_relevante_summ = []\n",
    "    lis_irrelevante_summ = []\n",
    "    \n",
    "    a_splitado = a.split()\n",
    "    tamanho_a_sem_repetição = len(list(set(a_splitado)))\n",
    "    \n",
    "    \n",
    "    for plvs in a_splitado:\n",
    "        str_relevante_count = relevante_series.str.count(plvs).sum()\n",
    "        str_irrelevante_count = irrelevante_series.str.count(plvs).sum()\n",
    "\n",
    "        if str_relevante_count == 0:\n",
    "            str_relevante_count = str_relevante_count + 1\n",
    "        else:\n",
    "            str_relevante_count = str_relevante_count\n",
    "        if str_irrelevante_count == 0:\n",
    "            str_irrelevante_count = str_irrelevante_count + 1\n",
    "        else:\n",
    "            str_irrelevante_count = str_irrelevante_count\n",
    "        lis_relevante_summ.append(str_relevante_count)\n",
    "        lis_irrelevante_summ.append(str_irrelevante_count)\n",
    "        \n",
    "    for vles in lis_relevante_summ:\n",
    "        prod_relevante = prod_relevante * (vles / (relevante_contado + tamanho_a_sem_repetição) )\n",
    "    for vls in lis_irrelevante_summ:\n",
    "        prod_irrelevante = prod_irrelevante * (vls / (irrelevante_contado + tamanho_a_sem_repetição) )\n",
    "    \n",
    "    return prod_relevante, prod_irrelevante"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Separando a planilha teste pré-categorizada"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "qualidade = list(teste_planilha.set_index('qual').index)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Estava dando erro nessas linhas da aba \"Teste\" da planilha, por isso separei as e coloquei na lista a baixo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "deu_errado = [6, 17, 40, 42, 47, 51, 61, 85]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "lista_teste_reindexado = list(teste_reindexado.index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "relevante_num = 0\n",
    "irrelevante_num = 0\n",
    "\n",
    "relevante_correto = 0\n",
    "relevante_incorreto = 0\n",
    "\n",
    "irrelevante_correto = 0\n",
    "irrelevante_incorreto = 0\n",
    "\n",
    "lista_teste_reindexado\n",
    "contador = 0\n",
    "while contador < len(lista_teste_reindexado):\n",
    "    if contador not in deu_errado:\n",
    "        a = lista_teste_reindexado[contador]\n",
    "        r,i = numero_string_series(relevante,irrelevante,a)\n",
    "        if r > i:\n",
    "            relevante_num = relevante_num + 1\n",
    "            if qualidade[contador] == 1:\n",
    "                relevante_correto = relevante_correto + 1\n",
    "            else:\n",
    "                relevante_incorreto = relevante_incorreto + 1\n",
    "        elif i > r:\n",
    "            irrelevante_num = irrelevante_num + 1\n",
    "            if qualidade[contador] == 0:\n",
    "                irrelevante_correto = irrelevante_correto + 1\n",
    "            else:\n",
    "                irrelevante_incorreto = irrelevante_incorreto + 1\n",
    "    contador = contador + 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Separando a probabilidade, última parte da árvore binária"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "verdadeiro_positivo = relevante_correto / (relevante_num + irrelevante_num)\n",
    "falso_positivo = relevante_incorreto / (relevante_num + irrelevante_num)\n",
    "verdadeiro_negativo = irrelevante_correto / (relevante_num + irrelevante_num)\n",
    "falso_negativo = irrelevante_incorreto / (relevante_num + irrelevante_num)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "soma = verdadeiro_positivo + verdadeiro_negativo + falso_positivo + falso_negativo"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Conclusão do projeto\n",
    "***\n",
    "* Parece que o classificado Naive-Bayes está funcionando, mas com alguns pequenos problemas que serão abordados no final deste projeto. Primeiramente gostaria de mostra que assim como no final de uma árvore de probabilidade, a soma da probabilidade nas últimas pontas tem sempre ser igual a 1, a soma dos Positivos (Falso Positivo e Verdadeiro Positivo) com os Negativos (Falso Negativo com Verdadeiro Negativo) também deram exatamente igual a 1.\n",
    "  * A maior dificuldade do projeto foi um erro que a função \"pd.Series.str.count(palavras).sum()\" utilizada em         str_relevante_count = relevante_series.str.count(plvs).sum(). Porque às vezes ocorre um erro onde a biblioteca pandas não consegue interpretar o \")\" e \"(\" e isso causa um erro no programa. Por isso eu tive que adicionar manualmente todos os tweets que deram errado em uma lista (com o nome deu_errado)\n",
    "\n",
    "* A performance foi bem satisfatória para uma primeira tentativa, e como a minha base de dados não foi muito bem selecionada (será abordado também no final deste projeto) o resultado foi um pouco comprometido. Os resultados obtidos foram:\n",
    "  * Falso Positivo: 21,79%\n",
    "  * Verdadeiro Positivo: 21,79%\n",
    "  * Falso Negativo: 29,49%\n",
    "  * Verdadeiro Negativo: 26,92%\n",
    " \n",
    "* Não tenho parâmetros de verificação para julgar se está ou não dentro do parâmetro necessário para ser considerado um bom Naive-Bayes\n",
    "  * Mas fiquei feliz com o resultado, pois o programa realiza exatamente pra que ele foi programado\n",
    "\n",
    "* Como a linguagem do computador é puramente técnica e é interpretada em bits, não há possibilidade do programa julgar que a palavra foi ou não utilizada com tom sarcástico. A dupla negação também entra no mesmo problema, e como está é uma situação dificíl até para seres humanos interpretarem, o programa sobre muito mais para entender\n",
    "  * Mas se utilizarmos artefatos de \"Machine Learning\" podemos ensinar um pouco do que é sarcasmo para o programa. Porém ainda seria dificultoso ensiná-lo a interpretar duplas negações, porque mesmo contando o número de \"nãos\" pode resultar em um total desastre\n",
    "\n",
    "* Se vocês gostaram deste projeto gostaria de dizer que eu tenho total transparência ao dizer o que eu estou fazendo, como vocês podem analisar os meus critérios de auto-avaliação são bem rigorosos e buscam sempres ser sinceros ao cliente. Mas o diferencial real deste projeto é que ele pode ser utilizado em outras áreas além da classificação de tweet. Com algumas pequenas modificações é possível utilizar o método Naive-Bayes para realizar um filtro anti-spam a serviço da sua empresa (que também pode ser utilizado para fins pessoais)\n",
    "***"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Pequeno adendo\n",
    "\n",
    "***\n",
    "***\n",
    "\n",
    "* Como a empresa utilizada para a análise foi a \"SpaceX\" do gênio empresário Elon Musk, as mesmas palavras apareciam frequentemente nas duas categorias ( tanto relevantes quanto irrelevantes). E ocorreu um evento tanto quanto inusitado, a descoberta de um asteróide com um valor gigantesco (alguns falam em quintilhões e outros quadrilhões) acalorou o ânimo dos usuários do twitter e acabou corrompendo a base de dados. Mas o resultado foi bem satisfatório\n",
    "\n",
    "\n",
    "***\n",
    "***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
